[cloudera@quickstart ~]$ cd Downloads/
[cloudera@quickstart Downloads]$ ls
pg11.txt  words.txt
[cloudera@quickstart Downloads]$ hadoop fs -copyFromLocal words.txt
[cloudera@quickstart Downloads]$ hadoop fs -ls
Found 2 items
-rw-r--r--   1 cloudera cloudera     167518 2016-04-08 09:11 pg11.txt
-rw-r--r--   1 cloudera cloudera    5458199 2016-04-08 09:27 words.txt
[cloudera@quickstart Downloads]$ hadoop jar /usr/jars/hadoop-examples.jar
An example program must be given as the first argument.
Valid program names are:
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
  dbcount: An example job that count the pageview counts from a database.
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
  grep: A map/reduce program that counts the matches of a regex in the input.
  join: A job that effects a join over sorted, equally partitioned datasets
  multifilewc: A job that counts words from several files.
  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
  randomwriter: A map/reduce program that writes 10GB of random data per node.
  secondarysort: An example defining a secondary sort to the reduce.
  sort: A map/reduce program that sorts the data written by the random writer.
  sudoku: A sudoku solver.
  teragen: Generate data for the terasort
  terasort: Run the terasort
  teravalidate: Checking results of terasort
  wordcount: A map/reduce program that counts the words in the input files.
  wordmean: A map/reduce program that counts the average length of the words in the input files.
  wordmedian: A map/reduce program that counts the median length of the words in the input files.
  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
[cloudera@quickstart Downloads]$ hadoop jar /usr/jars/hadoop-examples.jar wordmedian
Usage: wordmedian <in> <out>
[cloudera@quickstart Downloads]$ hadoop jar /usr/jars/hadoop-examples.jar wordmedian words.txt outwordmedian
16/04/08 09:30:06 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/04/08 09:30:07 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/08 09:30:08 INFO input.FileInputFormat: Total input paths to process : 1
16/04/08 09:30:08 INFO mapreduce.JobSubmitter: number of splits:1
16/04/08 09:30:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1460131084978_0001
16/04/08 09:30:09 INFO impl.YarnClientImpl: Submitted application application_1460131084978_0001
16/04/08 09:30:10 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1460131084978_0001/
16/04/08 09:30:10 INFO mapreduce.Job: Running job: job_1460131084978_0001
16/04/08 09:30:27 INFO mapreduce.Job: Job job_1460131084978_0001 running in uber mode : false
16/04/08 09:30:27 INFO mapreduce.Job:  map 0% reduce 0%
16/04/08 09:30:40 INFO mapreduce.Job:  map 100% reduce 0%
16/04/08 09:30:54 INFO mapreduce.Job:  map 100% reduce 100%
16/04/08 09:30:55 INFO mapreduce.Job: Job job_1460131084978_0001 completed successfully
16/04/08 09:30:55 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=296
		FILE: Number of bytes written=221439
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5458319
		HDFS: Number of bytes written=197
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=10773
		Total time spent by all reduces in occupied slots (ms)=10632
		Total time spent by all map tasks (ms)=10773
		Total time spent by all reduce tasks (ms)=10632
		Total vcore-seconds taken by all map tasks=10773
		Total vcore-seconds taken by all reduce tasks=10632
		Total megabyte-seconds taken by all map tasks=11031552
		Total megabyte-seconds taken by all reduce tasks=10887168
	Map-Reduce Framework
		Map input records=124456
		Map output records=901325
		Map output bytes=7210600
		Map output materialized bytes=296
		Input split bytes=120
		Combine input records=901325
		Combine output records=29
		Reduce input groups=29
		Reduce shuffle bytes=296
		Reduce input records=29
		Reduce output records=29
		Spilled Records=58
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=200
		CPU time spent (ms)=3610
		Physical memory (bytes) snapshot=339800064
		Virtual memory (bytes) snapshot=3007422464
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5458199
	File Output Format Counters 
		Bytes Written=197
The median is: 4
[cloudera@quickstart Downloads]$ 
