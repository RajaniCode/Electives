[cloudera@quickstart ~]$ hadoop jar /usr/jars/hadoop-examples.jar
An example program must be given as the first argument.
Valid program names are:
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
  dbcount: An example job that count the pageview counts from a database.
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
  grep: A map/reduce program that counts the matches of a regex in the input.
  join: A job that effects a join over sorted, equally partitioned datasets
  multifilewc: A job that counts words from several files.
  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
  randomwriter: A map/reduce program that writes 10GB of random data per node.
  secondarysort: An example defining a secondary sort to the reduce.
  sort: A map/reduce program that sorts the data written by the random writer.
  sudoku: A sudoku solver.
  teragen: Generate data for the terasort
  terasort: Run the terasort
  teravalidate: Checking results of terasort
  wordcount: A map/reduce program that counts the words in the input files.
  wordmean: A map/reduce program that counts the average length of the words in the input files.
  wordmedian: A map/reduce program that counts the median length of the words in the input files.
  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
[cloudera@quickstart ~]$ hadoop jar /usr/jars/hadoop-examples.jar grep
Grep <inDir> <outDir> <regex> [<group>]
Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

[cloudera@quickstart ~]$ hadoop jar /usr/jars/hadoop-examples.jar grep pg11.txt outgrep Cheshire
16/04/08 09:47:29 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/04/08 09:47:30 WARN mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/08 09:47:30 INFO input.FileInputFormat: Total input paths to process : 1
16/04/08 09:47:30 INFO mapreduce.JobSubmitter: number of splits:1
16/04/08 09:47:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1460131084978_0003
16/04/08 09:47:31 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
16/04/08 09:47:31 INFO impl.YarnClientImpl: Submitted application application_1460131084978_0003
16/04/08 09:47:31 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1460131084978_0003/
16/04/08 09:47:31 INFO mapreduce.Job: Running job: job_1460131084978_0003
16/04/08 09:47:44 INFO mapreduce.Job: Job job_1460131084978_0003 running in uber mode : false
16/04/08 09:47:44 INFO mapreduce.Job:  map 0% reduce 0%
16/04/08 09:47:53 INFO mapreduce.Job:  map 100% reduce 0%
16/04/08 09:48:05 INFO mapreduce.Job:  map 100% reduce 100%
16/04/08 09:48:05 INFO mapreduce.Job: Job job_1460131084978_0003 completed successfully
16/04/08 09:48:05 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=25
		FILE: Number of bytes written=221467
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=167637
		HDFS: Number of bytes written=111
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7334
		Total time spent by all reduces in occupied slots (ms)=8204
		Total time spent by all map tasks (ms)=7334
		Total time spent by all reduce tasks (ms)=8204
		Total vcore-seconds taken by all map tasks=7334
		Total vcore-seconds taken by all reduce tasks=8204
		Total megabyte-seconds taken by all map tasks=7510016
		Total megabyte-seconds taken by all reduce tasks=8400896
	Map-Reduce Framework
		Map input records=3735
		Map output records=7
		Map output bytes=119
		Map output materialized bytes=25
		Input split bytes=119
		Combine input records=7
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=25
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=182
		CPU time spent (ms)=1840
		Physical memory (bytes) snapshot=347815936
		Virtual memory (bytes) snapshot=3007381504
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=167518
	File Output Format Counters 
		Bytes Written=111
16/04/08 09:48:05 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
16/04/08 09:48:05 WARN mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/08 09:48:05 INFO input.FileInputFormat: Total input paths to process : 1
16/04/08 09:48:05 INFO mapreduce.JobSubmitter: number of splits:1
16/04/08 09:48:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1460131084978_0004
16/04/08 09:48:05 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
16/04/08 09:48:05 INFO impl.YarnClientImpl: Submitted application application_1460131084978_0004
16/04/08 09:48:05 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1460131084978_0004/
16/04/08 09:48:05 INFO mapreduce.Job: Running job: job_1460131084978_0004
16/04/08 09:48:18 INFO mapreduce.Job: Job job_1460131084978_0004 running in uber mode : false
16/04/08 09:48:18 INFO mapreduce.Job:  map 0% reduce 0%
16/04/08 09:48:27 INFO mapreduce.Job:  map 100% reduce 0%
16/04/08 09:48:37 INFO mapreduce.Job:  map 100% reduce 100%
16/04/08 09:48:38 INFO mapreduce.Job: Job job_1460131084978_0004 completed successfully
16/04/08 09:48:38 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=25
		FILE: Number of bytes written=220441
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=254
		HDFS: Number of bytes written=11
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7320
		Total time spent by all reduces in occupied slots (ms)=7838
		Total time spent by all map tasks (ms)=7320
		Total time spent by all reduce tasks (ms)=7838
		Total vcore-seconds taken by all map tasks=7320
		Total vcore-seconds taken by all reduce tasks=7838
		Total megabyte-seconds taken by all map tasks=7495680
		Total megabyte-seconds taken by all reduce tasks=8026112
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=17
		Map output materialized bytes=25
		Input split bytes=143
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=25
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=171
		CPU time spent (ms)=1650
		Physical memory (bytes) snapshot=350392320
		Virtual memory (bytes) snapshot=3007246336
		Total committed heap usage (bytes)=226365440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=111
	File Output Format Counters 
		Bytes Written=11
[cloudera@quickstart ~]$ hadoop fs -ls
Found 4 items
drwxr-xr-x   - cloudera cloudera          0 2016-04-08 09:48 outgrep
drwxr-xr-x   - cloudera cloudera          0 2016-04-08 09:30 outwordmedian
-rw-r--r--   1 cloudera cloudera     167518 2016-04-08 09:11 pg11.txt
-rw-r--r--   1 cloudera cloudera    5458199 2016-04-08 09:27 words.txt
[cloudera@quickstart ~]$ hadoop fs -ls outgrep
Found 2 items
-rw-r--r--   1 cloudera cloudera          0 2016-04-08 09:48 outgrep/_SUCCESS
-rw-r--r--   1 cloudera cloudera         11 2016-04-08 09:48 outgrep/part-r-00000
[cloudera@quickstart ~]$ hadoop fs -copyToLocal outgrep/part-r-00000 localgrep.txt
[cloudera@quickstart ~]$ more localgrep.txt
7	Cheshire
[cloudera@quickstart ~]$ hadoop fs -copyToLocal outgrep
[cloudera@quickstart ~]$
